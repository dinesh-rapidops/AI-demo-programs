{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import mxnet as mx\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import imshow\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from mxnet.gluon import data as gdata\n",
    "import sys\n",
    "import time\n",
    "from mxnet import gluon, init, autograd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "from gluoncv.utils import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = mx.gluon.data.vision.ImageFolderDataset(\"/Users/dinesh/python-test/flower_photos/train\", transform=lambda data, label: (data.astype(np.float32)/255, label))\n",
    "# test_dataset = mx.gluon.data.vision.ImageFolderDataset(\"/Users/dinesh/python-test/flower_photos/test\", transform=lambda data, label: (data.astype(np.float32)/255, label))\n",
    "train_dataset = mx.gluon.data.vision.ImageFolderDataset(\"/Users/dinesh/python-test/flower_photos/train\", transform=lambda data, label: (data.astype(np.float32)/255, label))\n",
    "test_dataset = mx.gluon.data.vision.ImageFolderDataset(\"/Users/dinesh/python-test/flower_photos/test\", transform=lambda data, label: (data.astype(np.float32)/255, label))\n",
    "# train_dataset = mx.gluon.data.vision.ImageFolderDataset(\"/Users/dinesh/python-test/flower_photos/train\", transform=lambda data, label: (data.astype(np.float32)/255, label))\n",
    "# test_dataset = mx.gluon.data.vision.ImageFolderDataset(\"/Users/dinesh/python-test/flower_photos/test\", transform=lambda data, label: (data.astype(np.float32)/255, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3309\n",
      "361\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "sample_idx = 1000\n",
    "sample = train_dataset[sample_idx]\n",
    "viz.plot_image(sample[0])\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "transformer = gdata.vision.transforms.Compose([gdata.vision.transforms.Resize(300), gdata.vision.transforms.CenterCrop(256),gdata.vision.transforms.ToTensor()])\n",
    "if sys.platform.startswith('win'):\n",
    "   # 0 means no additional processes are needed to speed up the reading of\n",
    "   # data\n",
    "   num_workers = 0\n",
    "else:\n",
    "   num_workers = 4\n",
    "\n",
    "train_iter = gdata.DataLoader( train_dataset.transform_first(transformer),\n",
    "   batch_size, shuffle=True,\n",
    "   num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader( test_dataset.transform_first(transformer),\n",
    "   batch_size, shuffle=False,\n",
    "   num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Model\n",
    "def init(net, optimizer='sgd', learning_rate=0.1, weight_decay=1e-6, ctx=mx.cpu()):\n",
    "   net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "   trainer = gluon.Trainer(net.collect_params(),\n",
    "                           optimizer,\n",
    "                           {'learning_rate': learning_rate, 'wd': weight_decay})\n",
    "   return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Accuracy\n",
    "def accuracy(data_iterator, net,ctx=mx.cpu()):\n",
    "   acc = mx.metric.Accuracy()\n",
    "   for (data, label) in data_iterator:\n",
    "       data = data.as_in_context(ctx)\n",
    "       label = label.as_in_context(ctx)\n",
    "       output = net(data)\n",
    "       predictions = mx.nd.argmax(output, axis=1)\n",
    "       acc.update(preds=predictions, labels=label)\n",
    "   return acc.get()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Model\n",
    "def train(net, trainer, train_data, validation_data, epochs, ctx=mx.cpu()):\n",
    "   training_accuracies = []\n",
    "   validation_accuracies = []\n",
    "   softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "   for e in range(epochs):\n",
    "       tic = time.time()\n",
    "       for (data, label) in train_data:\n",
    "           data  = data.as_in_context(ctx)\n",
    "           label = label.as_in_context(ctx)\n",
    "           with autograd.record():\n",
    "               output = net(data)\n",
    "               loss = softmax_cross_entropy(output, label)\n",
    "               loss.backward()\n",
    "           trainer.step(data.shape[0])\n",
    "       toc = time.time()\n",
    "       train_accuracy = accuracy(train_data, net)\n",
    "       training_accuracies.append(train_accuracy)\n",
    "       validation_accuracy = accuracy(validation_data, net)\n",
    "       validation_accuracies.append(validation_accuracy)\n",
    "       print(\"Epoch#%d Time=%.2f Training=%.4f Validation=%.4f Diff=%.4f\"\n",
    "             % (e, toc-tic, train_accuracy, validation_accuracy, train_accuracy-validation_accuracy))\n",
    "   return training_accuracies, validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "def plot_accuracies(training_accuracies, validation_accuracies):\n",
    "   epochs = len(training_accuracies)\n",
    "   plt.clf()\n",
    "   fig, ax = plt.subplots()\n",
    "   plt.xlabel('Epochs')\n",
    "   plt.ylabel('Accuracy')\n",
    "   train_plot, = ax.plot(range(epochs), training_accuracies, label=\"Training accuracy\")\n",
    "   validation_plot, = ax.plot(range(epochs), validation_accuracies, label=\"Validation accuracy\")\n",
    "   plt.legend(handles=[train_plot,validation_plot])\n",
    "   plt.xticks(np.arange(0, epochs, 5))\n",
    "   ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.4f'))\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dense(None -> 10, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(10))\n",
    "trainer = init(net)\n",
    "print(net)\n",
    "training_accuracies, validation_accuracies = train(net, trainer, train_iter, test_iter, 50)\n",
    "plot_accuracies(training_accuracies, validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
